#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Maps Business Scraper
×—×™×¤×•×© ×¢×¡×§×™× ×™×©×™×¨×•×ª ×-Google Maps
"""

import time
import json
import csv
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import requests
from urllib.parse import quote

class GoogleMapsScraper:
    def __init__(self, headless=True):
        """××ª×—×•×œ ×”×¡×§×¨×™×™×¤×¨"""
        self.setup_driver(headless)
        self.results = []
        
    def setup_driver(self, headless=True):
        """×”×’×“×¨×ª Chrome driver"""
        chrome_options = Options()
        if headless:
            chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.wait = WebDriverWait(self.driver, 10)
        
    def search_businesses(self, query, location="Israel", max_results=100):
        """×—×™×¤×•×© ×¢×¡×§×™× ×‘-Google Maps"""
        print(f"ğŸ” ××—×¤×©: {query} ×‘{location}")
        
        # ×‘× ×™×™×ª URL ×œ×—×™×¤×•×©
        search_query = f"{query} {location}"
        url = f"https://www.google.com/maps/search/{quote(search_query)}"
        
        print(f"ğŸŒ ×¤×•×ª×—: {url}")
        self.driver.get(url)
        
        # ×”××ª× ×” ×œ×˜×¢×™× ×ª ×”×ª×•×¦××•×ª
        time.sleep(3)
        
        # ×’×œ×™×œ×” ×œ×˜×¢×™× ×ª ×ª×•×¦××•×ª × ×•×¡×¤×•×ª
        self.scroll_for_results(max_results)
        
        # ×—×™×œ×•×¥ ×”×ª×•×¦××•×ª
        businesses = self.extract_business_data()
        
        print(f"âœ… × ××¦××• {len(businesses)} ×¢×¡×§×™×")
        return businesses
    
    def scroll_for_results(self, max_results):
        """×’×œ×™×œ×” ×œ×˜×¢×™× ×ª ×ª×•×¦××•×ª × ×•×¡×¤×•×ª"""
        print("ğŸ“œ ×’×•×œ×œ ×œ×˜×¢×™× ×ª ×ª×•×¦××•×ª...")
        
        # ××¦×™××ª ×¤×× ×œ ×”×ª×•×¦××•×ª
        try:
            results_panel = self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '[role="main"]'))
            )
        except TimeoutException:
            print("âŒ ×œ× × ××¦× ×¤×× ×œ ×ª×•×¦××•×ª")
            return
        
        last_height = 0
        scroll_attempts = 0
        max_scroll_attempts = 20
        
        while scroll_attempts < max_scroll_attempts:
            # ×’×œ×™×œ×” ×œ××˜×”
            self.driver.execute_script(
                "arguments[0].scrollTop = arguments[0].scrollHeight", 
                results_panel
            )
            
            time.sleep(2)
            
            # ×‘×“×™×§×ª ××¡×¤×¨ ×”×ª×•×¦××•×ª ×”× ×•×›×—×™
            current_results = len(self.driver.find_elements(By.CSS_SELECTOR, '[data-result-index]'))
            
            if current_results >= max_results:
                print(f"ğŸ¯ ×”×’×¢× ×• ×œ××¡×¤×¨ ×”×ª×•×¦××•×ª ×”××‘×•×§×©: {current_results}")
                break
                
            # ×‘×“×™×§×” ×× ×™×© ×¢×•×“ ×ª×•×¦××•×ª ×œ×˜×¢×•×Ÿ
            new_height = self.driver.execute_script(
                "return arguments[0].scrollHeight", results_panel
            )
            
            if new_height == last_height:
                scroll_attempts += 1
                print(f"â³ × ×™×¡×™×•×Ÿ ×’×œ×™×œ×” {scroll_attempts}/{max_scroll_attempts}")
            else:
                scroll_attempts = 0
                
            last_height = new_height
            
        print(f"ğŸ“Š ×¡×™×™×× ×• ×’×œ×™×œ×”. × ××¦××• {current_results} ×ª×•×¦××•×ª")
    
    def extract_business_data(self):
        """×—×™×œ×•×¥ × ×ª×•× ×™ ×”×¢×¡×§×™×"""
        businesses = []
        
        # ××¦×™××ª ×›×œ ×”×ª×•×¦××•×ª
        business_elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-result-index]')
        
        print(f"ğŸ”„ ××¢×‘×“ {len(business_elements)} ×¢×¡×§×™×...")
        
        for i, element in enumerate(business_elements):
            try:
                business_data = self.extract_single_business(element, i)
                if business_data:
                    businesses.append(business_data)
                    
            except Exception as e:
                print(f"âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×¢×¡×§ {i}: {str(e)}")
                continue
                
        return businesses
    
    def extract_single_business(self, element, index):
        """×—×™×œ×•×¥ × ×ª×•× ×™× ×©×œ ×¢×¡×§ ×™×—×™×“"""
        business = {
            'index': index + 1,
            'name': '',
            'address': '',
            'phone': '',
            'website': '',
            'rating': '',
            'reviews_count': '',
            'category': '',
            'hours': '',
            'price_level': '',
            'google_url': '',
            'scraped_at': datetime.now().isoformat()
        }
        
        try:
            # ×œ×—×™×¦×” ×¢×œ ×”×¢×¡×§ ×œ×¤×ª×™×—×ª ×”×¤×¨×˜×™×
            element.click()
            time.sleep(2)
            
            # ×©× ×”×¢×¡×§
            try:
                name_element = self.wait.until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'h1'))
                )
                business['name'] = name_element.text.strip()
            except:
                business['name'] = "×œ× × ××¦× ×©×"
            
            # ×›×ª×•×‘×ª
            try:
                address_element = self.driver.find_element(
                    By.CSS_SELECTOR, '[data-item-id="address"] .fontBodyMedium'
                )
                business['address'] = address_element.text.strip()
            except:
                pass
            
            # ×˜×œ×¤×•×Ÿ
            try:
                phone_element = self.driver.find_element(
                    By.CSS_SELECTOR, '[data-item-id*="phone"] .fontBodyMedium'
                )
                business['phone'] = phone_element.text.strip()
            except:
                pass
            
            # ××ª×¨ ××™× ×˜×¨× ×˜
            try:
                website_element = self.driver.find_element(
                    By.CSS_SELECTOR, '[data-item-id="authority"] a'
                )
                business['website'] = website_element.get_attribute('href')
            except:
                pass
            
            # ×“×™×¨×•×’ ×•×‘×™×§×•×¨×•×ª
            try:
                rating_element = self.driver.find_element(
                    By.CSS_SELECTOR, '.fontDisplayLarge'
                )
                business['rating'] = rating_element.text.strip()
                
                reviews_element = self.driver.find_element(
                    By.CSS_SELECTOR, '.fontBodyMedium .fontBodyMedium'
                )
                reviews_text = reviews_element.text.strip()
                # ×—×™×œ×•×¥ ××¡×¤×¨ ×”×‘×™×§×•×¨×•×ª
                reviews_match = re.search(r'(\d+)', reviews_text)
                if reviews_match:
                    business['reviews_count'] = reviews_match.group(1)
            except:
                pass
            
            # ×§×˜×’×•×¨×™×”
            try:
                category_element = self.driver.find_element(
                    By.CSS_SELECTOR, '.fontBodyMedium .fontBodyMedium'
                )
                business['category'] = category_element.text.strip()
            except:
                pass
            
            # ×©×¢×•×ª ×¤×¢×™×œ×•×ª
            try:
                hours_button = self.driver.find_element(
                    By.CSS_SELECTOR, '[data-item-id="oh"] .fontBodyMedium'
                )
                business['hours'] = hours_button.text.strip()
            except:
                pass
            
            # URL ×©×œ Google Maps
            business['google_url'] = self.driver.current_url
            
            print(f"âœ… {index + 1}. {business['name']} - {business['phone']}")
            
            return business
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×—×™×œ×•×¥ × ×ª×•× ×™×: {str(e)}")
            return None
    
    def save_to_csv(self, businesses, filename=None):
        """×©××™×¨×” ×œ×§×•×‘×¥ CSV"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"google_maps_results_{timestamp}.csv"
        
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            if not businesses:
                print("âŒ ××™×Ÿ × ×ª×•× ×™× ×œ×©××™×¨×”")
                return
                
            fieldnames = businesses[0].keys()
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for business in businesses:
                writer.writerow(business)
        
        print(f"ğŸ’¾ × ×©××¨ ×‘×§×•×‘×¥: {filename}")
        return filename
    
    def save_to_json(self, businesses, filename=None):
        """×©××™×¨×” ×œ×§×•×‘×¥ JSON"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"google_maps_results_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as jsonfile:
            json.dump(businesses, jsonfile, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ × ×©××¨ ×‘×§×•×‘×¥: {filename}")
        return filename
    
    def close(self):
        """×¡×’×™×¨×ª ×”×“×¤×“×¤×Ÿ"""
        if hasattr(self, 'driver'):
            self.driver.quit()

def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    print("ğŸš€ Google Maps Business Scraper")
    print("=" * 50)
    
    # ×”×’×“×¨×•×ª ×—×™×¤×•×©
    searches = [
        {"query": "×¨×”×™×˜×™×", "location": "×ª×œ ××‘×™×‘", "max_results": 50},
        {"query": "×¢×•×¨×›×™ ×“×™×Ÿ", "location": "×™×¨×•×©×œ×™×", "max_results": 30},
        {"query": "××¡×¢×“×•×ª", "location": "×—×™×¤×”", "max_results": 40},
    ]
    
    scraper = GoogleMapsScraper(headless=False)  # False ×›×“×™ ×œ×¨××•×ª ××ª ×”×“×¤×“×¤×Ÿ
    
    try:
        all_results = []
        
        for search in searches:
            print(f"\nğŸ” ××ª×—×™×œ ×—×™×¤×•×©: {search['query']} ×‘{search['location']}")
            
            results = scraper.search_businesses(
                query=search['query'],
                location=search['location'],
                max_results=search['max_results']
            )
            
            # ×”×•×¡×¤×ª ××™×“×¢ ×¢×œ ×”×—×™×¤×•×©
            for result in results:
                result['search_query'] = search['query']
                result['search_location'] = search['location']
            
            all_results.extend(results)
            
            print(f"âœ… ×”×•×©×œ× ×—×™×¤×•×©: {len(results)} ×ª×•×¦××•×ª")
            time.sleep(5)  # ×”××ª× ×” ×‘×™×Ÿ ×—×™×¤×•×©×™×
        
        # ×©××™×¨×ª ×”×ª×•×¦××•×ª
        if all_results:
            csv_file = scraper.save_to_csv(all_results)
            json_file = scraper.save_to_json(all_results)
            
            print(f"\nğŸ‰ ×¡×™×™×× ×•! × ××¦××• {len(all_results)} ×¢×¡×§×™× ×‘×¡×š ×”×›×œ")
            print(f"ğŸ“ ×§×‘×¦×™× × ×©××¨×•: {csv_file}, {json_file}")
        else:
            print("âŒ ×œ× × ××¦××• ×ª×•×¦××•×ª")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ×”×—×™×¤×•×© ×”×•×¤×¡×§ ×¢×œ ×™×“×™ ×”××©×ª××©")
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×›×œ×œ×™×ª: {str(e)}")
    finally:
        scraper.close()

if __name__ == "__main__":
    main()